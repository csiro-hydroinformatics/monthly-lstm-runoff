[
  {
    "objectID": "notebooks/tf_models.html",
    "href": "notebooks/tf_models.html",
    "title": "Introduction to using the ozrr package",
    "section": "",
    "text": "This vignette gives an introduction to using the ozrr package to define how to train an LTSM model for the simulation of monthly runoff.\nIt uses an arbitrary catchment and training hyperparameters, for illustrative purposes.\n\n\n\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport tensorflow as tf\nimport os\n\n2023-05-04 10:33:11.642840: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n\n\n\nfrom ozrr_data.repository import load_aus_rr_data\nfrom ozrr.tfmodels import CatchmentTraining, checked_mkdir, mk_model_filename\n\n\n# TODO later: use tensorboard\n#  %load_ext tensorboard\n\nUsually, deep learning training is much faster on GPUs, which can be tricky to get to work.\nHowever, in our particular use case (single catchment) training runs faster on a laptop CPU than a fairly decent GPU, about three times faster, as the parallelism offered by GPUs does not offer advantages. So, we will force the device to be a CPU, anyway.\n\ntf.config.list_physical_devices('GPU')\n\n[]\n\n\n\ntf.config.set_visible_devices([], \"GPU\")  # force CPU execution\n\n\ntf.config.get_visible_devices()\n\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n\n\n\n\n\nThe input dataset used in this paper takes the form of multiple comma separated value files. However this section “hides” this detail by using some helper classes and functions to load these into an xarray DataArray.\nOzrrPathFinder is not key to this vignette and you can ignore it.\n\nfrom ozrr._boilerplate import OzrrPathFinder\npf = OzrrPathFinder()\nroot_dir_f = pf.find_input_data_dir()\n\n\nroot_dir_out_f = os.path.expanduser(\"~/data/DWL/out/tftests\")\nroot_dir_out = Path(root_dir_out_f)\nif not root_dir_out.exists():\n    root_dir_out.mkdir(parents=True)\n\n\nroot_dir = Path(root_dir_f)\nout_dir = root_dir_out / \"tf_models\"\n\nOn the first call to load_aus_rr it may take around 3 minutes to ingest the hundreds CSV files, if from a local file system.\nHowever once done, the directory has a netcdf cached entry, and subsequent loading will only take a few seconds, and a fraction of a second with lazy loading.\n\n%%time \ndata_repo = load_aus_rr_data(root_dir_f, lazy_loading=True, do_aggregate=False)\n\nCPU times: user 133 ms, sys: 12.2 ms, total: 146 ms\nWall time: 177 ms\n\n\n\ndata_repo.ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset>\nDimensions:                            (time: 25933, series_id: 11, station: 951)\nCoordinates: (12/78)\n  * time                               (time) datetime64[ns] 1950-01-01 ... 2...\n  * series_id                          (series_id) object 'evap[mm/d]' ... 'r...\n  * station                            (station) object '809322' ... '237206'\n    lat                                (station) float64 ...\n    lon                                (station) float64 ...\n    AWRALid                            (station) float64 ...\n    ...                                 ...\n    runoff_prcnan[%]                   (station) float64 ...\n    runoff_ndays                       (station) int64 ...\n    runoff_prcinterp[%]                (station) float64 ...\n    runoff_nmaxdryspell                (station) int64 ...\n    year_month                         (time) object (1950, 1) ... (2020, 12)\n    year                               (time) int64 1950 1950 1950 ... 2020 2020\nData variables:\n    daily_series                       (station, time, series_id) float64 ...xarray.DatasetDimensions:time: 25933series_id: 11station: 951Coordinates: (78)time(time)datetime64[ns]1950-01-01 ... 2020-12-31array(['1950-01-01T00:00:00.000000000', '1950-01-02T00:00:00.000000000',\n       '1950-01-03T00:00:00.000000000', ..., '2020-12-29T00:00:00.000000000',\n       '2020-12-30T00:00:00.000000000', '2020-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')series_id(series_id)object'evap[mm/d]' ... 'runoff[mm/d]'array(['evap[mm/d]', 'AWRA_SS[mm]', 'TEMPmax[C]', 'AWRA_S0[mm]', 'TEMPmin[C]',\n       'AWRA_ETactual[mm/d]', 'rain[mm/d]', 'AWRA_Runoff[mm/d]',\n       'streamflow[ML/d]', 'runoff_linear_flag', 'runoff[mm/d]'], dtype=object)station(station)object'809322' '145' ... '237206'array(['809322', '145', '412065', ..., '802156', '204039', '237206'],\n      dtype=object)lat(station)float64...[951 values with dtype=float64]lon(station)float64...[951 values with dtype=float64]AWRALid(station)float64...[951 values with dtype=float64]BJPid(station)object...[951 values with dtype=object]HRSid(station)object...[951 values with dtype=object]HYFSid(station)object...[951 values with dtype=object]JVid(station)float64...[951 values with dtype=float64]KENNARD_flow_class(station)object...[951 values with dtype=object]KENNARDid(station)float64...[951 values with dtype=float64]NASYid(station)float64...[951 values with dtype=float64]QLDid(station)object...[951 values with dtype=object]SELECTEDid(station)float64...[951 values with dtype=float64]WAid(station)float64...[951 values with dtype=float64]WFSid(station)object...[951 values with dtype=object]all_names(station)object...[951 values with dtype=object]area[km2](station)float64...[951 values with dtype=float64]clim_climate_class(station)float64...[951 values with dtype=float64]climzone_climate_class(station)float64...[951 values with dtype=float64]koppen_climate_class(station)float64...[951 values with dtype=float64]lat_centroid(station)float64...[951 values with dtype=float64]lat_outlet(station)float64...[951 values with dtype=float64]lon_centroid(station)float64...[951 values with dtype=float64]lon_outlet(station)float64...[951 values with dtype=float64]station_name(station)object...[951 values with dtype=object]seasrain_climate_class(station)float64...[951 values with dtype=float64]sources(station)object...[951 values with dtype=object]state(station)object...[951 values with dtype=object]suspicious(station)object...[951 values with dtype=object]wiski_siteid(station)float64...[951 values with dtype=float64]area_corrected[km2](station)float64...[951 values with dtype=float64]lon_outlet_corrected(station)float64...[951 values with dtype=float64]lat_outlet_corrected(station)float64...[951 values with dtype=float64]comment(station)object...[951 values with dtype=object]area_hydstra[km2](station)float64...[951 values with dtype=float64]area_dem[km2](station)float64...[951 values with dtype=float64]lon_outlet_dem(station)float64...[951 values with dtype=float64]lat_outlet_dem(station)float64...[951 values with dtype=float64]lon_centroid_dem(station)float64...[951 values with dtype=float64]lat_centroid_dem(station)float64...[951 values with dtype=float64]alt_outlet_dem(station)float64...[951 values with dtype=float64]mean_pathlength[km](station)float64...[951 values with dtype=float64]max_pathlength[km](station)float64...[951 values with dtype=float64]mean_altitude_dem[m](station)float64...[951 values with dtype=float64]min_altitude_dem[m](station)float64...[951 values with dtype=float64]max_altitude_dem[m](station)float64...[951 values with dtype=float64]ibatch(station)int64...[951 values with dtype=int64]has_dam(station)bool...[951 values with dtype=bool]dam_capacity[ML](station)float64...[951 values with dtype=float64]WISKI_streamflow_start(station)object...[951 values with dtype=object]WISKI_streamflow_end(station)object...[951 values with dtype=object]WISKIid(station)object...[951 values with dtype=object]WISKIid_internal(station)object...[951 values with dtype=object]WISKIid_timeseries(station)object...[951 values with dtype=object]WISKI_streamflow_prcinterp[%](station)float64...[951 values with dtype=float64]WISKI_streamflow_prcnan[%](station)float64...[951 values with dtype=float64]country(station)object...[951 values with dtype=object]has_flood_waterbalance_problem(station)bool...[951 values with dtype=bool]has_longterm_waterbalance_problem(station)bool...[951 values with dtype=bool]has_runoff_interp_problem(station)bool...[951 values with dtype=bool]rain_start(station)float64...[951 values with dtype=float64]rain_end(station)float64...[951 values with dtype=float64]rain_prcnan[%](station)float64...[951 values with dtype=float64]rain_ndays(station)int64...[951 values with dtype=int64]evap_start(station)float64...[951 values with dtype=float64]evap_end(station)float64...[951 values with dtype=float64]evap_prcnan[%](station)float64...[951 values with dtype=float64]evap_ndays(station)int64...[951 values with dtype=int64]runoff_start(station)float64...[951 values with dtype=float64]runoff_end(station)float64...[951 values with dtype=float64]runoff_prcnan[%](station)float64...[951 values with dtype=float64]runoff_ndays(station)int64...[951 values with dtype=int64]runoff_prcinterp[%](station)float64...[951 values with dtype=float64]runoff_nmaxdryspell(station)int64...[951 values with dtype=int64]year_month(time)object(1950, 1) (1950, 1) ... (2020, 12)array([(1950, 1), (1950, 1), (1950, 1), ..., (2020, 12), (2020, 12),\n       (2020, 12)], dtype=object)year(time)int641950 1950 1950 ... 2020 2020 2020array([1950, 1950, 1950, ..., 2020, 2020, 2020])Data variables: (1)daily_series(station, time, series_id)float64...name :OZDATA dailyversion :1.0created :2020-07-27 11:10:09.301774author :jleratdescription :Rainfall and runoff data for OZDATA dataset prepared on 2020-07-27 11:10:08.967167[271285113 values with dtype=float64]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1950-01-01', '1950-01-02', '1950-01-03', '1950-01-04',\n               '1950-01-05', '1950-01-06', '1950-01-07', '1950-01-08',\n               '1950-01-09', '1950-01-10',\n               ...\n               '2020-12-22', '2020-12-23', '2020-12-24', '2020-12-25',\n               '2020-12-26', '2020-12-27', '2020-12-28', '2020-12-29',\n               '2020-12-30', '2020-12-31'],\n              dtype='datetime64[ns]', name='time', length=25933, freq=None))series_idPandasIndexPandasIndex(Index(['evap[mm/d]', 'AWRA_SS[mm]', 'TEMPmax[C]', 'AWRA_S0[mm]', 'TEMPmin[C]',\n       'AWRA_ETactual[mm/d]', 'rain[mm/d]', 'AWRA_Runoff[mm/d]',\n       'streamflow[ML/d]', 'runoff_linear_flag', 'runoff[mm/d]'],\n      dtype='object', name='series_id'))stationPandasIndexPandasIndex(Index(['809322', '145', '412065', '422338', '404208', '11203', '8140067',\n       '419054', '146002', '416048',\n       ...\n       '143001', '8150098', '416312', '206014', '120209', '117003', '8140001',\n       '802156', '204039', '237206'],\n      dtype='object', name='station', length=951))Attributes: (0)\n\n\n\ndata_repo.ds.series_id\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.DataArray 'series_id' (series_id: 11)>\narray(['evap[mm/d]', 'AWRA_SS[mm]', 'TEMPmax[C]', 'AWRA_S0[mm]', 'TEMPmin[C]',\n       'AWRA_ETactual[mm/d]', 'rain[mm/d]', 'AWRA_Runoff[mm/d]',\n       'streamflow[ML/d]', 'runoff_linear_flag', 'runoff[mm/d]'], dtype=object)\nCoordinates:\n  * series_id  (series_id) object 'evap[mm/d]' 'AWRA_SS[mm]' ... 'runoff[mm/d]'xarray.DataArray'series_id'series_id: 11'evap[mm/d]' 'AWRA_SS[mm]' ... 'runoff_linear_flag' 'runoff[mm/d]'array(['evap[mm/d]', 'AWRA_SS[mm]', 'TEMPmax[C]', 'AWRA_S0[mm]', 'TEMPmin[C]',\n       'AWRA_ETactual[mm/d]', 'rain[mm/d]', 'AWRA_Runoff[mm/d]',\n       'streamflow[ML/d]', 'runoff_linear_flag', 'runoff[mm/d]'], dtype=object)Coordinates: (1)series_id(series_id)object'evap[mm/d]' ... 'runoff[mm/d]'array(['evap[mm/d]', 'AWRA_SS[mm]', 'TEMPmax[C]', 'AWRA_S0[mm]', 'TEMPmin[C]',\n       'AWRA_ETactual[mm/d]', 'rain[mm/d]', 'AWRA_Runoff[mm/d]',\n       'streamflow[ML/d]', 'runoff_linear_flag', 'runoff[mm/d]'], dtype=object)Indexes: (1)series_idPandasIndexPandasIndex(Index(['evap[mm/d]', 'AWRA_SS[mm]', 'TEMPmax[C]', 'AWRA_S0[mm]', 'TEMPmin[C]',\n       'AWRA_ETactual[mm/d]', 'rain[mm/d]', 'AWRA_Runoff[mm/d]',\n       'streamflow[ML/d]', 'runoff_linear_flag', 'runoff[mm/d]'],\n      dtype='object', name='series_id'))Attributes: (0)\n\n\n\n\n\nThe ozrr package includes provision to make sure outcomes are deterministic (broadly speaking by using seeds as argument to tensorflow functions). However, some states in Tensorflow seem to be global, so we also need a static call to tf.random.set_seed.\n\n## GLOBAL SEED ##\ntf.random.set_seed(123456)\nTRAINING_SEED = 42\n\n\n\n\n\nstation_id = \"405218\"\n\nCatchmentTraining is a high level class that deals with setting up the model and data to use for the fitting, hiding the tedium.\n\nmodel_dir = checked_mkdir(out_dir / \"models\")\nmodel_file = mk_model_filename(model_dir, station_id, with_timestamp=False)\nct = CatchmentTraining(out_dir, station_id, data_repo, model_file=model_file)\n\neval_end_date is an approximation given the end date of the input climate data set for most, but not all catchments.\nThe data handling module in ozrr deals with trailing missing values to find the correct last full month of data prior to that for aggregation, e.g. 2020-06-30, or 2020-05-31.\nct.conf is a CatchmentTrainingConfig object\n\nct.conf.eval_end_date = pd.Timestamp(\"2020-07-15\")\n\n\nct.conf.stateful = False\n\nct.fit_verbosity = 0  # https://www.tensorflow.org/api_docs/python/tf/keras/Model\nct.eval_verbosity = 0  # https://www.tensorflow.org/api_docs/python/tf/keras/Model\n\n# Force a reload of the data; we may have changed the time span specifications.\n# will be refactored later\n# ct.reload_data()\nfrom ozrr.tfmodels import lstm_single\n\n2023-01-30: trying to reproduce some unexpectly disappointing results on a round of batch calibrations.\n\nct.conf.n_epochs=100\nct.conf.train_start_date=pd.Timestamp(\"1950-01-01\")\nct.conf.train_end_date=pd.Timestamp(\"1995-12-31\")\nct.conf.eval_start_date=pd.Timestamp(\"1996-01-01\")\nct.conf.eval_end_date=pd.Timestamp(\"2020-07-15\")\nct.conf.batch_size=24\nct.conf.seq_length=6\nct.conf.num_features=3\nct.conf.feature_ids=[\"rain\", \"pet\", \"eff_rain\"]\nct.conf.steps_per_epoch=100\nct.conf.shuffle=True\nct.conf.stride=1\nct.conf.lstm_dim=10\nct.conf.logging=\"false\" # false (default), tensorboard, wandb\nct.conf.log_dir=\"ignored\" # directory for log output\nct.conf.use_validation=False # Should there be a training/validation split of the calibration period as a strategy to prevent model overfitting. \nct.conf.early_stopping=False\nct.conf.early_stopping_patience=14\nct.conf.lr_patience=3\nct.conf.lr_factor=0.5\nct.conf.lr_start=0.05\nct.conf.dropout=0.1\nct.conf.recurrent_dropout=0.1\n\nmodel_func needs to be reset AFTER the settings above. This will trigger the creation of the model with newer parameters. This is a design compromise resulting from legacy.\n\nct.conf.model_func = \"lstm_single\"\n\n\n# ds = data_repo.data_for_station(station_id)\n\nA data object holds the observations aggregated to monthly, and their scaled version\n\nx = ct.scaled_training_data()\n\n\nx.x\n\n\n\n\n\n  \n    \n      \n      rain\n      pet\n      eff_rain\n    \n    \n      t\n      \n      \n      \n    \n  \n  \n    \n      1959-03-31\n      -0.532426\n      0.385026\n      -0.694146\n    \n    \n      1959-04-30\n      -0.353701\n      -0.483118\n      -0.176882\n    \n    \n      1959-05-31\n      -1.363860\n      -0.914580\n      -1.096170\n    \n    \n      1959-06-30\n      -0.063804\n      -1.247830\n      0.144238\n    \n    \n      1959-07-31\n      -0.692425\n      -1.207809\n      -0.478399\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995-08-31\n      -0.734161\n      -0.792916\n      -0.617635\n    \n    \n      1995-09-30\n      -0.598107\n      -0.459398\n      -0.619684\n    \n    \n      1995-10-31\n      0.358981\n      0.254840\n      0.339624\n    \n    \n      1995-11-30\n      -0.270291\n      0.471712\n      -0.604118\n    \n    \n      1995-12-31\n      -1.142052\n      1.325237\n      -1.035516\n    \n  \n\n442 rows × 3 columns\n\n\n\n\nif model_file.exists(): model_file.unlink()\n\n\nimport tensorflow as tf\nimport logging\n\n# Set the verbosity level to 'WARNING' or 'ERROR' to suppress the output\ntf.get_logger().setLevel(logging.WARNING)\n\n\n%%time \nresult = ct.train(random_seed=TRAINING_SEED)\n\n2023-05-04 10:36:29.324729: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n\n\nCPU times: user 45.5 s, sys: 2.89 s, total: 48.4 s\nWall time: 21 s\n\n\n\nct.training_result.params\n\n{'verbose': 0, 'epochs': 100, 'steps': 100}\n\n\n\n_ = ct.evaluate()\n\n288/288 [==============================] - 0s 647us/step\n\n\n\n# save predictions\nct.save_verif_report = False\nct.generate_report()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Monthly runoff LSTM",
    "section": "",
    "text": "This site contains information about the computational material used for the paper Deep learning for monthly rainfall-runoff modelling: a comparison with classical rainfall-runoff modelling across Australia.\n\n\n\nExploratory dashboard for model comparison\n\n\nYou will find instructions to install the software environment and packages.\n\n\nAcknowledgements\nThis work is undertaken under the Digital Water and Landscape initiative in CSIRO Environment."
  },
  {
    "objectID": "documentation.html",
    "href": "documentation.html",
    "title": "Sample workflows",
    "section": "",
    "text": "Sample workflows for modellers\n\nIntroduction to using the ozrr package"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "getting-set-up.html",
    "href": "getting-set-up.html",
    "title": "Getting set up",
    "section": "",
    "text": "This document outlines the steps to create an environment suitable to run the material in this repository."
  },
  {
    "objectID": "getting-set-up.html#conda-environment",
    "href": "getting-set-up.html#conda-environment",
    "title": "Getting set up",
    "section": "conda environment",
    "text": "conda environment\nThere are various options to set up a suitable python environment to run . This document outlines using conda. If you do not have any preexisting environments, we recommend you use mambaforge.\nThis document assumes you start from the base environment, for instance in the “Anaconda/miniconda prompt”:\nxxxyyy@machine:~$ mamba env list\n# conda environments:\n#\nbase                     /home/xxxyyy/mambaforge\nWe recommend you use the mamba command, a newer drop-in replacement for conda. This is optional. In an existing conda environment you can do conda install -c conda-forge mamba. Mambaforge comes already with mamba, of course.\nTo set up a new conda environment usable as a kernel by the notebook(s) in this repository, you may use the following environment specification."
  },
  {
    "objectID": "getting-set-up.html#c-compiler",
    "href": "getting-set-up.html#c-compiler",
    "title": "Getting set up",
    "section": "C++ compiler",
    "text": "C++ compiler\nWe use the hydrodiy package as a dependency. On Windows you will need a Microsoft Visual C++ compiler 14.0 or greater installed. If you have MS Visual Studio 2015 or newer with C++ options installed, this should work. If you do not have Visual Studio, there are various options to install the C++ build tools from the Visual Studio Download page. You do not need to install the full Visual Studio installation, we just need command line build tools including C++ compiler.\nOn other platforms than Windows, typically you can very easily install the GNU g++ compiler and it is usually available by default."
  },
  {
    "objectID": "getting-set-up.html#on-windows",
    "href": "getting-set-up.html#on-windows",
    "title": "Getting set up",
    "section": "On Windows:",
    "text": "On Windows:\n:: from within your \"(base)\" conda environment\n:: You can call your environment as you wish, it need not be ozrr:\nset my_env_name=ozrr\ncd c:\\src\\monthly-lstm-runoff\\ozrr\\configs\n:: if you have mamba installed in your base environment:\nwhere mamba\nmamba env create -n %my_env_name% -f ./environment.yml\n:: otherwise use the significantly slower\n:: conda env create -n %my_env_name% -f ./environment.yml\n:: may take quite some time...\nIf you see a Failed to build hydrodiy warning and error, see the Troubleshooting section below"
  },
  {
    "objectID": "getting-set-up.html#on-linux",
    "href": "getting-set-up.html#on-linux",
    "title": "Getting set up",
    "section": "On Linux:",
    "text": "On Linux:\n# from within your \"(base)\" conda environment\n# You can call your environment as you wish, it need not be ozrr:\nmy_env_name=ozrr\ncd ~/src/monthly-lstm-runoff/ozrr/configs\n# if you have mamba installed in your base environment:\nwhich mamba\nmamba env create -n $my_env_name -f ./environment.yml\n# otherwise use the significantly slower\n# conda env create -n $my_env_name -f ./environment.yml\n# may take quite some time...\nIf you see a Failed to build hydrodiy warning and error, see the Troubleshooting section below"
  },
  {
    "objectID": "getting-set-up.html#troubleshooting",
    "href": "getting-set-up.html#troubleshooting",
    "title": "Getting set up",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nWith the environment.yml file we crafted you should not have trouble with the above instructions. One issue previously encountered is documented for the record only.\nIf you see an error such as the following output when creating the environment, some of our packages may have failed to install:\nFailed to build hydrodiy\n\nPip subprocess error:\n  Running command git clone --filter=blob:none --quiet https://bitbucket.org/jm75/hydrodiy /tmp/pip-install-9tsb5jcx/hydrodiy_3a3aa800601f4d0aa85302bc962faa5c\n  WARNING: Built wheel for hydrodiy is invalid: Metadata 1.2 mandates PEP 440 version, but '.2.2-251.ge446bfa' is not\nERROR: Could not build wheels for hydrodiy, which is required to install pyproject.toml-based projects\n\nfailed\n\nCondaEnvException: Pip failed\nThis can happen depending on how a specified source in the conda environment.yml for a package retrieved from git. git describe may return something like v.2.2-289-g9e84708 which creates issues.\nThe newly created environment should contain two packages added from source: mamba activate ozrr and mamba list | grep pypi lists:\nhydrodiy                  2.2.1                    pypi_0    pypi\nozrr-data                 0.5                      pypi_0    pypi\nIf these are missing, you can work around this installing ozrr-data and hydrodiy for instance like so:\nconda activate $my_env_name\ncd ~/src/ozrr-data/\npip install -e ."
  },
  {
    "objectID": "getting-set-up.html#wapaba",
    "href": "getting-set-up.html#wapaba",
    "title": "Getting set up",
    "section": "WAPABA",
    "text": "WAPABA\nThis section is optional\nSimulation for the WAPABA model were done using a larger system known as swift2. This software in not entirely open source, but a binary installation can be made available on demand via email.\nFollow the swift installation instructions.\nIf installing python packages from source, all packages installed in develop mode:\ncd ~/src/pyrefcount\npip install -e .\ncd ~/src/c-interop/bindings/python/cinterop\npip install -e .\ncd ~/src/datatypes/bindings/python/uchronia\npip install -e .\ncd ~/src/swift/bindings/python/swift2/\npip install -e ."
  },
  {
    "objectID": "getting-set-up.html#ozrr-package",
    "href": "getting-set-up.html#ozrr-package",
    "title": "Getting set up",
    "section": "ozrr package",
    "text": "ozrr package\ncd ~/src/monthly-lstm-runoff\npip install -e ozrr/"
  },
  {
    "objectID": "ozrr/docs/tech_notes.html",
    "href": "ozrr/docs/tech_notes.html",
    "title": "Monthly runoff LSTM",
    "section": "",
    "text": "These are notes for the package maintainer(s). Most users can ignore them.\nNote to self: as of Jan 2019 also using github_jm_how.md to log the exploratory and release processes around refcount\n\n\n\nall UT pass\nMerge new features/fixes to devel branch.\nversion.py updated\ncheck readme is up to date\n\n\n\n\ncd ${HOME}/src/github/camels-aus-py\nsource ${HOME}/anaconda3/bin/activate\n#my_env_name=efts\nmy_env_name=camels\nconda create --name ${my_env_name} python=3.9\nconda activate ${my_env_name}\nconda install -c conda-forge wheel twine six pytest \nconda activate ${my_env_name}\ncd ${HOME}/src/github_jm/camels-aus-py\nmkdir -p dist\nrm dist/*\npython3 setup.py sdist bdist_wheel\nrm dist/*.tar\nImportantly to not end up with incorrect display of the readme:\ntwine check dist/*\ntwine upload --repository-url https://test.pypi.org/legacy/ dist/*\nThen and only then:\ntwine upload dist/*\n\n\n\n2021-01 Exploring options for putting this on readthedoc. I used in the past sphinx with napoleon extensions to document ela. This was a trial run. Did something more substantial for an internal project (WAA).\nStarting afresh with this, reading the RTD guides. Introduces mkdocs. Notice this blog on mkdocs-material which seems like the new cool kid on the block.\nUnclear from RTD where to create a new mkdocs project (supposed to be in the root of the python package?) not sure. for now:\ncd doc\nmkdir mkd\ncd mkd/\nmkdocs new .\nmamba install -c conda-forge mkdocs-material mkdocstrings mkdocs-material-extensions\n\n\n\npandoc -f markdown -t rst README.md  > README.rst\nCan view with the retext program (did not find VScode RST extensions working, or giving out blank output if not, perhaps)\npython setup.py check --restructuredtext"
  },
  {
    "objectID": "ozrr/docs/index.html",
    "href": "ozrr/docs/index.html",
    "title": "Monthly runoff LSTM",
    "section": "",
    "text": "This is currently a preview. You can contribute to features and design\n\nPython package to easily load and use the OZ-DATA dataset (Fowler, K. J. A. et al. 2020 (in review))\nOZ-DATA is the Australian edition of the Catchment Attributes and Meteorology for Large-sample Studies.\n\n\n\n\n\nLoading OZ-DATA from a notebook\n\n\n\n\nBSD-3 (see License)\n\n\n\nThe code repository is on GitHub.\n\n\n\n\n\nUsing a conda environment is recommended. To create a new environment:\ncd ${HOME}/tmp\nwget https://raw.githubusercontent.com/csiro-hydroinformatics/camels-aus-py/main/configs/ozrr_environment.yml\nmy_env_name=camels\nonda env create -n $my_env_name -f ./ozrr_environment.yml\nconda activate $my_env_name \nThen:\npip install ozrr\nIf installing from source, after checking out this git repo:\npip install -r requirements.txt # if not using conda\npython setup.py install\nDevelopers:\npython setup.py develop\n\n\n\noptional but recommended: use mamba as a replacement for conda: conda install -c conda-forge --name ${my_env_name} mamba\nmamba install -c conda-forge jupyterlab ipywidgets jupyter ipyleaflet\npython -m ipykernel install --user --name ${my_env_name} --display-name \"CAMELS\"\njupyter-lab .\n\n\n\n\n\n\nNormally jupyter-lab version 3.0 and more does not require explicit extensions installation, but if you have issues:\nif: “Loading widgets…”\njupyter-labextension install @jupyter-widgets/jupyterlab-manager\nif: “Error displaying widget: model not found”\njupyter-labextension install @jupyter-widgets/jupyterlab-manager"
  },
  {
    "objectID": "ozrr/docs/code-reference.html",
    "href": "ozrr/docs/code-reference.html",
    "title": "Monthly runoff LSTM",
    "section": "",
    "text": "You are likely to need only to look at the repository module to manage your resources.\n\n\n::: ozrr.repository\n\n\n\n::: ozrr.conventions"
  }
]